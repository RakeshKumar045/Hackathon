{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "from collections import Counter , defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "from pandas import Series as s , DataFrame as df\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from matplotlib import pyplot as plt, rcParams as rc\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "rc[\"figure.figsize\"] = 10,6\n",
    "\n",
    "import datetime\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.model_selection  import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from iteration_utilities import duplicates, unique_everseen\n",
    "\n",
    "import sys\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from timeit import timeit\n",
    "\n",
    "\n",
    "## RandomOverSampler to handle imbalanced data\n",
    "from imblearn.over_sampling import RandomOverSampler # over sampling method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Algorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, recall_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_recall_fscore_support\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# GridSearchCV to find optimal min_samples_leaf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((131662, 14), (87395, 13), (87395, 2))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train_Wc8LBpr.csv\")\n",
    "\n",
    "df_test = pd.read_csv(\"test_VsU9xXK.csv\")\n",
    "submission = pd.read_csv(\"sample_submission_NoPBkjr.csv\")\n",
    "\n",
    "df10 = df.copy()\n",
    "df.shape, df_test.shape, submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentage_miss_value(dataset):\n",
    "    higher_miss_value_column = []\n",
    "    miss_threshold_value = 50\n",
    "    \n",
    "    for i in dataset.columns:\n",
    "        if dataset[i].isna().sum() > 1: \n",
    "            perectange_val = (dataset[i].isna().sum() / len(dataset)) * 100\n",
    "            print(\"Column-> \" , i, \", total no of missing value : \",dataset[i].isna().sum() , \" & :         \", round(perectange_val,2) ,\" %\")\n",
    "                \n",
    "            if(perectange_val > miss_threshold_value):\n",
    "                higher_miss_value_column.append(i)\n",
    "            \n",
    "    print(\"\\n\\n\\n\")\n",
    "    \n",
    "    if higher_miss_value_column:\n",
    "        print(\"Higher Missing values in Columns for Delete : \", higher_miss_value_column)\n",
    "    else:\n",
    "        print(\"There are no Higher Column Missing values in Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_percentage_miss_value(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_percentage_miss_value(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cloumn_details_type_categorical(dataset):\n",
    "    for i in dataset.columns:\n",
    "        if(dataset[i].dtype == \"object\"):\n",
    "            print(\"Columns name :  \",i  )\n",
    "            \n",
    "            print(dict(Counter(dataset[i])))\n",
    "            \n",
    "            print(\"*\"*100)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_cloumn_details_type_categorical(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7131898345764154"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "93900 / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_cloumn_details_type_categorical(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cloumn_details_type_numberical(dataset):\n",
    "    for i in dataset.columns:\n",
    "        if (dataset[i].dtype == \"int\"):\n",
    "            print(\"Columns name :  \",i  )\n",
    "            \n",
    "            print(dict(Counter(dataset[i])))\n",
    "            print(\"*\"*100)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            \n",
    "def check_cloumn_details_type_float(dataset):\n",
    "    for i in dataset.columns:\n",
    "        if (dataset[i].dtype == \"float\"):\n",
    "            print(\"Columns name :  \",i  )\n",
    "            \n",
    "            print(dict(Counter(dataset[i])))\n",
    "            print(\"*\"*100)\n",
    "            print(\"\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_cloumn_details_type_numberical(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_cloumn_details_type_float(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulazing the distibution of the data for every feature\n",
    "def visualize_hist(dataset):\n",
    "    dataset.hist(edgecolor='black', linewidth=1.2, figsize=(20, 20));\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize_hist(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_histogram(dataset):\n",
    "    # plot histogram\n",
    "    plt.figure(figsize=(25, 9))  # figure size in ratio 16:9\n",
    "    features = dataset.columns  # list of columns name\n",
    "    for i, j in enumerate(features):\n",
    "        plt.subplot(3, 3, i + 1)  # create subplot for histogram\n",
    "        plt.title(\"Histogram of {}\".format(j), fontsize=15)  # title of histogram\n",
    "\n",
    "        bins = len(dataset[j].unique())  # bins for histogram\n",
    "        plt.hist(dataset[j], bins=bins, rwidth=0.8, edgecolor=\"y\", linewidth=2, )  # plot histogram\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.5)  # space between horixontal axes (subplots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_histogram(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'telecom_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-b666539c3f3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtelecom_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arpu_6'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'arpu_7'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'arpu_8'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'churn_flag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'churn_flag'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvisualize_pairplot_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumberical_col_list\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtarget_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'telecom_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "def corr_metrix(dataset):\n",
    "    corr = dataset.corr()\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap='RdYlGn')\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5});\n",
    "    ax.tick_params(labelsize=20)\n",
    "\n",
    "def corr_2_more_visualize(dataset):\n",
    "    corr = dataset.corr()\n",
    "    \n",
    "    f, ax = plt.subplots(figsize=(20, 9))\n",
    "    sns.heatmap(corr.apply(lambda x : np.round(x,2)), \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values,annot=True,cmap='RdYlGn', annot_kws={\"size\": 15})\n",
    "    ax.tick_params(labelsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def linear_regression_train_test():\n",
    "    #Linear regression with L2 regularization\n",
    "    for i in range(-2, 3):\n",
    "        alpha = 10**i\n",
    "        rm = Ridge(alpha = alpha)\n",
    "        ridge_model = rm.fit(X_train, y_train)\n",
    "        preds_ridge = ridge_model.predict(X_test)\n",
    "    \n",
    "        plt.scatter(preds_ridge, y_test, alpha= 0.75, c= 'b')\n",
    "        plt.xlabel('Predicted price')\n",
    "        plt.ylabel('Actual price')\n",
    "        plt.title('Ridge redularization with alpha {}'.format(alpha))\n",
    "        overlay = 'R square: {} \\nRMSE: {}'.format(ridge_model.score(X_test, y_test), mean_squared_error(y_test, preds_ridge))\n",
    "        plt.annotate(s = overlay, xy = (12.1, 10.6), size = 'x-large')\n",
    "        plt.show()\n",
    "        \n",
    "def actual_predict_visualization(actual_values, predict_values):\n",
    "    plt.scatter(actual_values, predict_values, alpha= 0.75, color = 'b')\n",
    "\n",
    "    plt.xlabel('Predicted price')\n",
    "    plt.ylabel('Actual price')\n",
    "    plt.title('Regression Model')\n",
    "    plt.show()\n",
    "    \n",
    "def visualize_original_predict_test(X_val, Y_val, default = \"Test\"):\n",
    "    print(\"Dataset type  : \\n\" ,default)\n",
    "    plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
    "    plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)\n",
    "\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    \n",
    "    plt.xlabel(\"X axis\", color = \"red\")\n",
    "    plt.ylabel(\"Y axis\", color = \"green\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def visualize_categorical_values(dataset):\n",
    "    no_of_columns = 4\n",
    "    no_of_rows = 4\n",
    "    \n",
    "    columns_object_type = [i for i in dataset.columns  if dataset[i].dtype == \"object\"]\n",
    "    total_rows = (len(columns_object_type) // no_of_rows ) + 1\n",
    "    \n",
    "    f, axes = plt.subplots(total_rows, no_of_columns, figsize=(18,24))\n",
    "\n",
    "    for ind, val in enumerate(columns_object_type):\n",
    "        sns.countplot(df[val] , ax = axes[ind // no_of_rows , ind %no_of_columns ])\n",
    "    plt.show()   \n",
    "    \n",
    "sns.pairplot(data = telecom_df[['arpu_6','arpu_7','arpu_8','churn_flag']],hue = 'churn_flag')\n",
    "\n",
    "def visualize_pairplot_target(numberical_col_list , target_val):\n",
    "    plt.figure(figsize=(18,34))\n",
    "    sns.pairplot(data = telecom_df[numberical_col_list],hue = target_val)\n",
    "    \n",
    "    #     sns.pairplot(data = telecom_df[['arpu_6','arpu_7','arpu_8','churn_flag']],hue = 'churn_flag') \n",
    "    #check for classification\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def visualize_numberical_values(dataset):\n",
    "    plt.figure(figsize=(18,34))\n",
    "    sns.pairplot(df)\n",
    "    plt.show()\n",
    "# visualize_numberical_values(df)\n",
    "    \n",
    "def check_skewness_numerical(dataset, target):\n",
    "    #analysing the distribution of sale price\n",
    "    print('skew is', dataset.SalePrice.skew())   \n",
    "    plt.hist(dataset[target], color= 'b')\n",
    "\n",
    "    plt.title('Distribution of ' + target, fontsize = 24)\n",
    "    plt.ylabel('observation', fontsize = 20)\n",
    "    plt.xlabel(target, fontsize = 20)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def skewness_after_log_transform(dataset , target):\n",
    "    #log transforming sale price to transform it into gaussian distribution\n",
    "    target1 = np.log(dataset.target)\n",
    "    print('skew is', target1.skew())\n",
    "    plt.hist(target, color= 'b')\n",
    "\n",
    "    plt.title('Distribution of ' + target, fontsize = 24)\n",
    "    plt.ylabel('observation', fontsize = 20)\n",
    "    plt.xlabel(target , fontsize = 20)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "# Since pairplots for all numeric values together are not clear we can make groups ,do plot with price & analyse\n",
    "\n",
    "def pair_plot(list_4_numberical_values):\n",
    "    sns.pairplot(df2, x_vars= list_4_numberical_values, y_vars='SalePrice',size=4, kind='scatter')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131662, 14)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_2_more_visualize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_categorical_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_numberical_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label encoding\n",
    "def convert_to_numerical_datatype_train(dataset):\n",
    "    enc = LabelEncoder()\n",
    "    for i in dataset.columns:\n",
    "        if(dataset[i].dtype == \"object\"):\n",
    "            dataset[i] = enc.fit_transform(dataset[i])\n",
    "            \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Impute missing values.\n",
    "\n",
    "        Columns of dtype object are imputed with the most frequent value \n",
    "        in column.\n",
    "\n",
    "        Columns of other types are imputed with mean of column.\n",
    "\n",
    "        \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0] if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n",
    "            index=X.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='green' > EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = [\"Trip_ID\" , \"Var1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((131662, 14), (131662, 12))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.drop(columns = drop_col)\n",
    "df.shape , df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((87395, 13), (87395, 11))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_test = df_test.drop(columns = drop_col)\n",
    "df_test.shape , df1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= DataFrameImputer().fit_transform(df1)\n",
    "\n",
    "\n",
    "df2_test = DataFrameImputer().fit_transform(df1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isna().sum().sum(), df2_test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((131662, 12), (131662, 12))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = convert_to_numerical_datatype_train(df2)\n",
    "df2.shape, df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((87395, 11), (87395, 11))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_test = convert_to_numerical_datatype_train(df2_test)\n",
    "df2_test.shape, df3_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardscaler_preprocessing(dataset_train, dataset_test, num_col):\n",
    "    scaler = StandardScaler()\n",
    "   \n",
    "    dataset_train[num_col] = scaler.fit_transform(dataset_train[num_col])\n",
    "\n",
    "    dataset_test[num_col] = scaler.transform(dataset_test[num_col])\n",
    "    \n",
    "    return dataset_train, dataset_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_col = [\"Trip_Distance\" , \"Customer_Since_Months\" , \"Life_Style_Index\", \"Customer_Rating\", \"Var2\", \"Var3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4, df4_test = standardscaler_preprocessing(df3, df3_test, scaling_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df4.iloc[:,:-1]\n",
    "\n",
    "Y = df4.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109.23 0.31 44.20090853853045\n",
      "10.0 0.0 6.016661099712109\n",
      "4.87511 1.59638 2.8020639999461827\n",
      "5.0 0.00125 2.849457958636489\n"
     ]
    }
   ],
   "source": [
    "print( df[\"Trip_Distance\"].max() , df[\"Trip_Distance\"].min() , df[\"Trip_Distance\"].mean())\n",
    "\n",
    "print( df[\"Customer_Since_Months\"].max() , df[\"Customer_Since_Months\"].min() , df[\"Customer_Since_Months\"].mean())\n",
    "\n",
    "print( df[\"Life_Style_Index\"].max() , df[\"Life_Style_Index\"].min() , df[\"Life_Style_Index\"].mean())\n",
    "\n",
    "print( df[\"Customer_Rating\"].max() , df[\"Customer_Rating\"].min() , df[\"Customer_Rating\"].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip_Distance</th>\n",
       "      <th>Type_of_Cab</th>\n",
       "      <th>Customer_Since_Months</th>\n",
       "      <th>Life_Style_Index</th>\n",
       "      <th>Confidence_Life_Style_Index</th>\n",
       "      <th>Destination_Type</th>\n",
       "      <th>Customer_Rating</th>\n",
       "      <th>Cancellation_Last_1Month</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.466568</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.415378</td>\n",
       "      <td>-1.801959e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.076346</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.043456</td>\n",
       "      <td>-1.304086</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.577167</td>\n",
       "      <td>1</td>\n",
       "      <td>1.123841</td>\n",
       "      <td>-9.440728e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612378</td>\n",
       "      <td>0</td>\n",
       "      <td>0.962110</td>\n",
       "      <td>0.250555</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.102689</td>\n",
       "      <td>1</td>\n",
       "      <td>1.123841</td>\n",
       "      <td>3.633778e-14</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.664638</td>\n",
       "      <td>2</td>\n",
       "      <td>0.962110</td>\n",
       "      <td>0.164186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.680141</td>\n",
       "      <td>2</td>\n",
       "      <td>1.123841</td>\n",
       "      <td>3.633778e-14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.616202</td>\n",
       "      <td>0</td>\n",
       "      <td>0.159884</td>\n",
       "      <td>-0.094921</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.421157</td>\n",
       "      <td>2</td>\n",
       "      <td>1.123841</td>\n",
       "      <td>1.118919e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.441786</td>\n",
       "      <td>2.323410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trip_Distance  Type_of_Cab  Customer_Since_Months  Life_Style_Index  \\\n",
       "0      -1.466568            1              -1.415378     -1.801959e+00   \n",
       "1      -0.577167            1               1.123841     -9.440728e-02   \n",
       "2      -0.102689            1               1.123841      3.633778e-14   \n",
       "3       0.680141            2               1.123841      3.633778e-14   \n",
       "4       0.421157            2               1.123841      1.118919e+00   \n",
       "\n",
       "   Confidence_Life_Style_Index  Destination_Type  Customer_Rating  \\\n",
       "0                            0                 0         1.076346   \n",
       "1                            1                 0         0.612378   \n",
       "2                            1                 4         0.664638   \n",
       "3                            1                 0         0.616202   \n",
       "4                            1                 0         0.563942   \n",
       "\n",
       "   Cancellation_Last_1Month      Var2      Var3  Gender  \n",
       "0                         0 -1.043456 -1.304086       0  \n",
       "1                         0  0.962110  0.250555       1  \n",
       "2                         2  0.962110  0.164186       1  \n",
       "3                         0  0.159884 -0.094921       1  \n",
       "4                         4 -0.441786  2.323410       1  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_train_val , y_pred_val , dataset_type = \"Default\"):\n",
    "    \n",
    "    print(\" Dataset type is : \", dataset_type)\n",
    "    \n",
    "    print(\"\\n Accuracy Score     : \",round(accuracy_score(y_train_val, y_pred_val), 4) * 100)\n",
    "    \n",
    "    print(\"\\n precision_accuracy : \",round(precision_score(y_train_val, y_pred_val), 4) * 100)\n",
    " \n",
    "    print(\"\\n recall_accuracy    : \",round(recall_score(y_train_val, y_pred_val), 4) * 100)\n",
    "    \n",
    "    print(\"\\n roc_auc_accuracy   : \",round(roc_auc_score(y_train_val, y_pred_val), 4) * 100)\n",
    "    \n",
    "    print(\"\\n f1_score_accuracy  : \",round(f1_score(y_train_val, y_pred_val), 4) * 100)\n",
    "    \n",
    "    print(\"\\n explained_variance  : \",round(explained_variance_score(y_train_val, y_pred_val), 4) * 100)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_train_val, y_pred_val).ravel()\n",
    "    \n",
    "    print(\"\\n Confusion Matrix TN : \", tn, \" FP : \", fp, \" FN : \", fn, \" TP : \", tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows=[]\n",
    "\n",
    "def addRandomStateForAlgorithm(x,y,names,algorithms,columns_name,random_state_list):    \n",
    "    for j in range(len(algorithms)):\n",
    "        model = algorithms[j]\n",
    "        for i in random_state_list:\n",
    "            \n",
    "            x_train, x_test , y_train , y_test = train_test_split(x ,y , test_size = 0.30 , random_state = i)\n",
    "            \n",
    "            model.fit(x_train,y_train)\n",
    "            \n",
    "            y_pred_train = model.predict(x_train)\n",
    "            y_pred = model.predict(x_test)\n",
    "            \n",
    "            train_acc = accuracy_score(y_train, y_pred_train)\n",
    "            train_acc = round(train_acc, 4) * 100\n",
    "            \n",
    "            test_acc = accuracy_score(y_test, y_pred)\n",
    "            test_acc = round(test_acc, 4) * 100\n",
    "            \n",
    "#             roc_auc_score_acc = roc_auc_score(y_test, y_pred)\n",
    "#             roc_auc_score_acc = round(roc_auc_score_acc, 4) * 100\n",
    "            \n",
    "\n",
    "#             row = [names[j],   i,   train_acc, test_acc, roc_auc_score_acc]\n",
    "            row = [names[j],   i,   train_acc, test_acc]\n",
    "    \n",
    "            rows.append(row)\n",
    "            \n",
    "    models_df = pd.DataFrame(rows) \n",
    "    \n",
    "    models_df.columns = columns_name\n",
    "    print(models_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Model  Random_state  Train_acc  Test_acc\n",
      "0  XGBClassifier             1      69.48     68.88\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "# names_regression = [ \"LightGBM\", \"RF\", \"XGBoost\" , \"SVM\"]\n",
    "# algorithms = [ LGBMClassifier(), RandomForestClassifier(), XGBClassifier(), SVC()]\n",
    "\n",
    "# columns_name = [\"Model\",    \"Random_state\",   'Train_acc',     \"Test_acc\" , \"roc_auc_score\"]\n",
    "\n",
    "names_regression = [ \"XGBClassifier\"]\n",
    "algorithms = [ XGBClassifier(max_depth=5, objective='multi:softmax', num_classes=3)]\n",
    "\n",
    "columns_name = [\"Model\",    \"Random_state\",   'Train_acc',     \"Test_acc\" ]\n",
    "\n",
    "\n",
    "random_state_list_up_to_10 = [1]\n",
    "\n",
    "\n",
    "addRandomStateForAlgorithm(X,Y,names_regression,algorithms,columns_name,random_state_list_up_to_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_final = XGBClassifier(\n",
    "#  learning_rate =0.1,\n",
    "#  n_estimators=1000,\n",
    "#  max_depth=5,\n",
    "#  min_child_weight=1,\n",
    "#  gamma=0,\n",
    "#  subsample=0.8,\n",
    "#  colsample_bytree=0.8,\n",
    "#  objective= 'binary:logistic',\n",
    "#  nthread=4,\n",
    "#  scale_pos_weight=1,\n",
    "#  seed=27)\n",
    "\n",
    "model_final = XGBClassifier(max_depth=5, objective='multi:softmax', num_classes=3)\n",
    "\n",
    "\n",
    "model_final.fit(X, Y)\n",
    "\n",
    "y_pred_final = model_final.predict(df4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87395, 13) (87395, 2) 87395\n"
     ]
    }
   ],
   "source": [
    "submission_1 = submission.copy()\n",
    "\n",
    "print(df_test.shape , submission.shape , len(y_pred_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 ... 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "submission_1[\"Surge_Pricing_Type\"] = y_pred_final\n",
    "\n",
    "print(submission_1[\"Surge_Pricing_Type\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "submission_1.to_csv('submission_9_XGBoost_Sacle.csv', index=False)\n",
    "\n",
    "df_submission_1 = pd.read_csv('submission_9_XGBoost_Sacle.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87395, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip_ID</th>\n",
       "      <th>Surge_Pricing_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T0005689459</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T0005689462</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T0005689463</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Trip_ID  Surge_Pricing_Type\n",
       "0  T0005689459                   1\n",
       "1  T0005689462                   2\n",
       "2  T0005689463                   2"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_submission_1.shape)\n",
    "\n",
    "df_submission_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((131662, 14), (87395, 13))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape , df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44267"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "131662 - 87395"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train : train is a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset : train & test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Trip_ID', 'Trip_Distance', 'Type_of_Cab', 'Customer_Since_Months',\n",
       "       'Life_Style_Index', 'Confidence_Life_Style_Index', 'Destination_Type',\n",
       "       'Customer_Rating', 'Cancellation_Last_1Month', 'Var1', 'Var2', 'Var3',\n",
       "       'Gender', 'Surge_Pricing_Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 56728, 3: 47720, 1: 27214})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df.Surge_Pricing_Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((87395, 12), (44267, 12))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[0:87395].shape  , df3[87395 : ].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_imbalanced_dataset(dataset, target_col):\n",
    "    feature_columns = dataset.columns.tolist()\n",
    "    feature_columns = [c for c in feature_columns if c not in [target_col]]\n",
    "\n",
    "    X2 = dataset[feature_columns]\n",
    "    Y2 = dataset[target_col]\n",
    "\n",
    "    os =  RandomOverSampler(random_state=35)\n",
    "    X_feature_variables , y_output = os.fit_sample(X2, Y2)\n",
    "    \n",
    "    return X_feature_variables , y_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feature_variables1 , y_output1 = majority_imbalanced_dataset(df3, \"Surge_Pricing_Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10 = X_feature_variables1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10[\"Surge_Pricing_Type\"] = y_output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip_Distance</th>\n",
       "      <th>Type_of_Cab</th>\n",
       "      <th>Customer_Since_Months</th>\n",
       "      <th>Life_Style_Index</th>\n",
       "      <th>Confidence_Life_Style_Index</th>\n",
       "      <th>Destination_Type</th>\n",
       "      <th>Customer_Rating</th>\n",
       "      <th>Cancellation_Last_1Month</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Surge_Pricing_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.466568</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.415378</td>\n",
       "      <td>-1.801959e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.076346</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.043456</td>\n",
       "      <td>-1.304086</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.577167</td>\n",
       "      <td>1</td>\n",
       "      <td>1.123841</td>\n",
       "      <td>-9.440728e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612378</td>\n",
       "      <td>0</td>\n",
       "      <td>0.962110</td>\n",
       "      <td>0.250555</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.102689</td>\n",
       "      <td>1</td>\n",
       "      <td>1.123841</td>\n",
       "      <td>3.633778e-14</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.664638</td>\n",
       "      <td>2</td>\n",
       "      <td>0.962110</td>\n",
       "      <td>0.164186</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.680141</td>\n",
       "      <td>2</td>\n",
       "      <td>1.123841</td>\n",
       "      <td>3.633778e-14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.616202</td>\n",
       "      <td>0</td>\n",
       "      <td>0.159884</td>\n",
       "      <td>-0.094921</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.421157</td>\n",
       "      <td>2</td>\n",
       "      <td>1.123841</td>\n",
       "      <td>1.118919e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.441786</td>\n",
       "      <td>2.323410</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trip_Distance  Type_of_Cab  Customer_Since_Months  Life_Style_Index  \\\n",
       "0      -1.466568            1              -1.415378     -1.801959e+00   \n",
       "1      -0.577167            1               1.123841     -9.440728e-02   \n",
       "2      -0.102689            1               1.123841      3.633778e-14   \n",
       "3       0.680141            2               1.123841      3.633778e-14   \n",
       "4       0.421157            2               1.123841      1.118919e+00   \n",
       "\n",
       "   Confidence_Life_Style_Index  Destination_Type  Customer_Rating  \\\n",
       "0                            0                 0         1.076346   \n",
       "1                            1                 0         0.612378   \n",
       "2                            1                 4         0.664638   \n",
       "3                            1                 0         0.616202   \n",
       "4                            1                 0         0.563942   \n",
       "\n",
       "   Cancellation_Last_1Month      Var2      Var3  Gender  Surge_Pricing_Type  \n",
       "0                         0 -1.043456 -1.304086       0                   2  \n",
       "1                         0  0.962110  0.250555       1                   2  \n",
       "2                         2  0.962110  0.164186       1                   2  \n",
       "3                         0  0.159884 -0.094921       1                   3  \n",
       "4                         4 -0.441786  2.323410       1                   2  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((170184, 12), (131662, 12))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df10.shape , df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = df10[0:87395]\n",
    "\n",
    "new_train = df10[87395 : ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train = new_train.iloc[:, :-1]\n",
    "y1_train = new_train.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_test = new_test.iloc[:, :-1]\n",
    "y1_test = new_test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = XGBClassifier(max_depth=5, objective='multi:softmax', num_classes=3)\n",
    "\n",
    "\n",
    "model_final.fit(x1_train, y1_train)\n",
    "\n",
    "\n",
    "y_pred_final_new_train = model_final.predict(x1_train)\n",
    "\n",
    "# y_pred_final_new_test = model_final.predict(x1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87395"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final_new_test = model_final.predict(df3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset type is :  Train\n",
      "\n",
      " Accuracy Score     :  69.41000000000001\n",
      "[[32209  3577  2880]\n",
      " [ 7132  7910  3973]\n",
      " [ 3632  4130 17346]]\n"
     ]
    }
   ],
   "source": [
    "get_accuracy(y1_train , y_pred_final_new_train ,  \"Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset type is :  Test\n",
      "\n",
      " Accuracy Score     :  32.190000000000005\n",
      "[[ 6722  4775  6565]\n",
      " [14185  9913 13615]\n",
      " [11743  8379 11498]]\n"
     ]
    }
   ],
   "source": [
    "get_accuracy(y1_test , y_pred_final_new_test ,  \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset type is :  Their Test\n",
      "\n",
      " Accuracy Score     :  37.980000000000004\n",
      "[[ 2570 10011  5481]\n",
      " [ 5323 21140 11250]\n",
      " [ 4447 17693  9480]]\n"
     ]
    }
   ],
   "source": [
    "get_accuracy(y1_test , y_pred_final_new_test ,  \"Their Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_train_val , y_pred_val , dataset_type = \"Default\"):\n",
    "    \n",
    "    print(\" Dataset type is : \", dataset_type)\n",
    "    \n",
    "    print(\"\\n Accuracy Score     : \",round(accuracy_score(y_train_val, y_pred_val), 4) * 100)\n",
    "    \n",
    "#     print(\"\\n precision_accuracy : \",round(precision_score(y_train_val, y_pred_val), 4) * 100)\n",
    " \n",
    "#     print(\"\\n recall_accuracy    : \",round(recall_score(y_train_val, y_pred_val), 4) * 100)\n",
    "    \n",
    "#     print(\"\\n roc_auc_accuracy   : \",round(roc_auc_score(y_train_val, y_pred_val), 4) * 100)\n",
    "    \n",
    "#     print(\"\\n f1_score_accuracy  : \",round(f1_score(y_train_val, y_pred_val), 4) * 100)\n",
    "    \n",
    "#     print(\"\\n explained_variance  : \",round(explained_variance_score(y_train_val, y_pred_val), 4) * 100)\n",
    "    \n",
    "#     tn, fp, fn, tp = confusion_matrix(y_train_val, y_pred_val).ravel()\n",
    "    \n",
    "#     print(\"\\n Confusion Matrix TN : \", tn, \" FP : \", fp, \" FN : \", fn, \" TP : \", tp)\n",
    "    print(confusion_matrix(y_train_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_new[\"Surge_Pricing_Type\"] = y_pred_final_new_test\n",
    "\n",
    "\n",
    "submission_new.to_csv('submission_new_imbalance.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((87395, 2), (87395, 2))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_new.shape , submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
