{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "from collections import Counter , defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "from pandas import Series as s , DataFrame as df\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from matplotlib import pyplot as plt, rcParams as rc\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "rc[\"figure.figsize\"] = 10,6\n",
    "\n",
    "import datetime\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.model_selection  import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from iteration_utilities import duplicates, unique_everseen\n",
    "\n",
    "import sys\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from timeit import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Algorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, recall_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_recall_fscore_support\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# GridSearchCV to find optimal min_samples_leaf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((131662, 14), (87395, 13), (87395, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train_Wc8LBpr.csv\")\n",
    "\n",
    "df_test = pd.read_csv(\"test_VsU9xXK.csv\")\n",
    "submission = pd.read_csv(\"sample_submission_NoPBkjr.csv\")\n",
    "\n",
    "df10 = df.copy()\n",
    "df.shape, df_test.shape, submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentage_miss_value(dataset):\n",
    "    higher_miss_value_column = []\n",
    "    miss_threshold_value = 50\n",
    "    \n",
    "    for i in dataset.columns:\n",
    "        if dataset[i].isna().sum() > 1: \n",
    "            perectange_val = (dataset[i].isna().sum() / len(dataset)) * 100\n",
    "            print(\"Column-> \" , i, \", total no of missing value : \",dataset[i].isna().sum() , \" & :         \", round(perectange_val,2) ,\" %\")\n",
    "                \n",
    "            if(perectange_val > miss_threshold_value):\n",
    "                higher_miss_value_column.append(i)\n",
    "            \n",
    "    print(\"\\n\\n\\n\")\n",
    "    \n",
    "    if higher_miss_value_column:\n",
    "        print(\"Higher Missing values in Columns for Delete : \", higher_miss_value_column)\n",
    "    else:\n",
    "        print(\"There are no Higher Column Missing values in Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_percentage_miss_value(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_percentage_miss_value(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cloumn_details_type_categorical(dataset):\n",
    "    for i in dataset.columns:\n",
    "        if(dataset[i].dtype == \"object\"):\n",
    "            print(\"Columns name :  \",i  )\n",
    "            \n",
    "            print(dict(Counter(dataset[i])))\n",
    "            \n",
    "            print(\"*\"*100)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_cloumn_details_type_categorical(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7131898345764154"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "93900 / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_cloumn_details_type_categorical(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cloumn_details_type_numberical(dataset):\n",
    "    for i in dataset.columns:\n",
    "        if (dataset[i].dtype == \"int\"):\n",
    "            print(\"Columns name :  \",i  )\n",
    "            \n",
    "            print(dict(Counter(dataset[i])))\n",
    "            print(\"*\"*100)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            \n",
    "def check_cloumn_details_type_float(dataset):\n",
    "    for i in dataset.columns:\n",
    "        if (dataset[i].dtype == \"float\"):\n",
    "            print(\"Columns name :  \",i  )\n",
    "            \n",
    "            print(dict(Counter(dataset[i])))\n",
    "            print(\"*\"*100)\n",
    "            print(\"\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_cloumn_details_type_numberical(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_cloumn_details_type_float(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulazing the distibution of the data for every feature\n",
    "def visualize_hist(dataset):\n",
    "    dataset.hist(edgecolor='black', linewidth=1.2, figsize=(20, 20));\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize_hist(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_histogram(dataset):\n",
    "    # plot histogram\n",
    "    plt.figure(figsize=(25, 9))  # figure size in ratio 16:9\n",
    "    features = dataset.columns  # list of columns name\n",
    "    for i, j in enumerate(features):\n",
    "        plt.subplot(3, 3, i + 1)  # create subplot for histogram\n",
    "        plt.title(\"Histogram of {}\".format(j), fontsize=15)  # title of histogram\n",
    "\n",
    "        bins = len(dataset[j].unique())  # bins for histogram\n",
    "        plt.hist(dataset[j], bins=bins, rwidth=0.8, edgecolor=\"y\", linewidth=2, )  # plot histogram\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.5)  # space between horixontal axes (subplots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_histogram(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'telecom_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b666539c3f3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtelecom_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arpu_6'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'arpu_7'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'arpu_8'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'churn_flag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'churn_flag'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvisualize_pairplot_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumberical_col_list\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtarget_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'telecom_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "def corr_metrix(dataset):\n",
    "    corr = dataset.corr()\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap='RdYlGn')\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5});\n",
    "    ax.tick_params(labelsize=20)\n",
    "\n",
    "def corr_2_more_visualize(dataset):\n",
    "    corr = dataset.corr()\n",
    "    \n",
    "    f, ax = plt.subplots(figsize=(20, 9))\n",
    "    sns.heatmap(corr.apply(lambda x : np.round(x,2)), \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values,annot=True,cmap='RdYlGn', annot_kws={\"size\": 15})\n",
    "    ax.tick_params(labelsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def linear_regression_train_test():\n",
    "    #Linear regression with L2 regularization\n",
    "    for i in range(-2, 3):\n",
    "        alpha = 10**i\n",
    "        rm = Ridge(alpha = alpha)\n",
    "        ridge_model = rm.fit(X_train, y_train)\n",
    "        preds_ridge = ridge_model.predict(X_test)\n",
    "    \n",
    "        plt.scatter(preds_ridge, y_test, alpha= 0.75, c= 'b')\n",
    "        plt.xlabel('Predicted price')\n",
    "        plt.ylabel('Actual price')\n",
    "        plt.title('Ridge redularization with alpha {}'.format(alpha))\n",
    "        overlay = 'R square: {} \\nRMSE: {}'.format(ridge_model.score(X_test, y_test), mean_squared_error(y_test, preds_ridge))\n",
    "        plt.annotate(s = overlay, xy = (12.1, 10.6), size = 'x-large')\n",
    "        plt.show()\n",
    "        \n",
    "def actual_predict_visualization(actual_values, predict_values):\n",
    "    plt.scatter(actual_values, predict_values, alpha= 0.75, color = 'b')\n",
    "\n",
    "    plt.xlabel('Predicted price')\n",
    "    plt.ylabel('Actual price')\n",
    "    plt.title('Regression Model')\n",
    "    plt.show()\n",
    "    \n",
    "def visualize_original_predict_test(X_val, Y_val, default = \"Test\"):\n",
    "    print(\"Dataset type  : \\n\" ,default)\n",
    "    plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
    "    plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)\n",
    "\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    \n",
    "    plt.xlabel(\"X axis\", color = \"red\")\n",
    "    plt.ylabel(\"Y axis\", color = \"green\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def visualize_categorical_values(dataset):\n",
    "    no_of_columns = 4\n",
    "    no_of_rows = 4\n",
    "    \n",
    "    columns_object_type = [i for i in dataset.columns  if dataset[i].dtype == \"object\"]\n",
    "    total_rows = (len(columns_object_type) // no_of_rows ) + 1\n",
    "    \n",
    "    f, axes = plt.subplots(total_rows, no_of_columns, figsize=(18,24))\n",
    "\n",
    "    for ind, val in enumerate(columns_object_type):\n",
    "        sns.countplot(df[val] , ax = axes[ind // no_of_rows , ind %no_of_columns ])\n",
    "    plt.show()   \n",
    "    \n",
    "sns.pairplot(data = telecom_df[['arpu_6','arpu_7','arpu_8','churn_flag']],hue = 'churn_flag')\n",
    "\n",
    "def visualize_pairplot_target(numberical_col_list , target_val):\n",
    "    plt.figure(figsize=(18,34))\n",
    "    sns.pairplot(data = telecom_df[numberical_col_list],hue = target_val)\n",
    "    \n",
    "    #     sns.pairplot(data = telecom_df[['arpu_6','arpu_7','arpu_8','churn_flag']],hue = 'churn_flag') \n",
    "    #check for classification\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def visualize_numberical_values(dataset):\n",
    "    plt.figure(figsize=(18,34))\n",
    "    sns.pairplot(df)\n",
    "    plt.show()\n",
    "# visualize_numberical_values(df)\n",
    "    \n",
    "def check_skewness_numerical(dataset, target):\n",
    "    #analysing the distribution of sale price\n",
    "    print('skew is', dataset.SalePrice.skew())   \n",
    "    plt.hist(dataset[target], color= 'b')\n",
    "\n",
    "    plt.title('Distribution of ' + target, fontsize = 24)\n",
    "    plt.ylabel('observation', fontsize = 20)\n",
    "    plt.xlabel(target, fontsize = 20)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def skewness_after_log_transform(dataset , target):\n",
    "    #log transforming sale price to transform it into gaussian distribution\n",
    "    target1 = np.log(dataset.target)\n",
    "    print('skew is', target1.skew())\n",
    "    plt.hist(target, color= 'b')\n",
    "\n",
    "    plt.title('Distribution of ' + target, fontsize = 24)\n",
    "    plt.ylabel('observation', fontsize = 20)\n",
    "    plt.xlabel(target , fontsize = 20)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "# Since pairplots for all numeric values together are not clear we can make groups ,do plot with price & analyse\n",
    "\n",
    "def pair_plot(list_4_numberical_values):\n",
    "    sns.pairplot(df2, x_vars= list_4_numberical_values, y_vars='SalePrice',size=4, kind='scatter')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_2_more_visualize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_categorical_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_numberical_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label encoding\n",
    "def convert_to_numerical_datatype_train(dataset):\n",
    "    enc = LabelEncoder()\n",
    "    for i in dataset.columns:\n",
    "        if(dataset[i].dtype == \"object\"):\n",
    "            dataset[i] = enc.fit_transform(dataset[i])\n",
    "            \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Impute missing values.\n",
    "\n",
    "        Columns of dtype object are imputed with the most frequent value \n",
    "        in column.\n",
    "\n",
    "        Columns of other types are imputed with mean of column.\n",
    "\n",
    "        \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0] if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n",
    "            index=X.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='green' > EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = [\"Trip_ID\" , \"Var1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((131662, 14), (131662, 12))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.drop(columns = drop_col)\n",
    "df.shape , df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((87395, 13), (87395, 11))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_test = df_test.drop(columns = drop_col)\n",
    "df_test.shape , df1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= DataFrameImputer().fit_transform(df1)\n",
    "\n",
    "\n",
    "df2_test = DataFrameImputer().fit_transform(df1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isna().sum().sum(), df2_test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((131662, 12), (131662, 12))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = convert_to_numerical_datatype_train(df2)\n",
    "df2.shape, df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((87395, 11), (87395, 11))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_test = convert_to_numerical_datatype_train(df2_test)\n",
    "df2_test.shape, df3_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df3.iloc[:,:-1]\n",
    "\n",
    "Y = df3.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardscaler_preprocessing(dataset_train, dataset_test, num_col):\n",
    "    scaler = StandardScaler()\n",
    "   \n",
    "    dataset_train[num_col] = scaler.fit_transform(dataset_train[num_col])\n",
    "\n",
    "    dataset_test[num_col] = scaler.transform(dataset_test[num_col])\n",
    "    \n",
    "    return dataset_train, dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_train_val , y_pred_val , dataset_type = \"Default\"):\n",
    "    \n",
    "    print(\" Dataset type is : \", dataset_type)\n",
    "    \n",
    "    print(\"\\n Accuracy Score     : \",round(accuracy_score(y_train_val, y_pred_val), 4) * 100)\n",
    "    \n",
    "    print(\"\\n precision_accuracy : \",round(precision_score(y_train_val, y_pred_val), 4) * 100)\n",
    " \n",
    "    print(\"\\n recall_accuracy    : \",round(recall_score(y_train_val, y_pred_val), 4) * 100)\n",
    "    \n",
    "    print(\"\\n roc_auc_accuracy   : \",round(roc_auc_score(y_train_val, y_pred_val), 4) * 100)\n",
    "    \n",
    "    print(\"\\n f1_score_accuracy  : \",round(f1_score(y_train_val, y_pred_val), 4) * 100)\n",
    "    \n",
    "    print(\"\\n explained_variance  : \",round(explained_variance_score(y_train_val, y_pred_val), 4) * 100)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_train_val, y_pred_val).ravel()\n",
    "    \n",
    "    print(\"\\n Confusion Matrix TN : \", tn, \" FP : \", fp, \" FN : \", fn, \" TP : \", tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows=[]\n",
    "\n",
    "def addRandomStateForAlgorithm(x,y,names,algorithms,columns_name,random_state_list):    \n",
    "    for j in range(len(algorithms)):\n",
    "        model = algorithms[j]\n",
    "        for i in random_state_list:\n",
    "            \n",
    "            x_train, x_test , y_train , y_test = train_test_split(x ,y , test_size = 0.30 , random_state = i)\n",
    "            \n",
    "            model.fit(x_train,y_train)\n",
    "            \n",
    "            y_pred_train = model.predict(x_train)\n",
    "            y_pred = model.predict(x_test)\n",
    "            \n",
    "            train_acc = accuracy_score(y_train, y_pred_train)\n",
    "            train_acc = round(train_acc, 4) * 100\n",
    "            \n",
    "            test_acc = accuracy_score(y_test, y_pred)\n",
    "            test_acc = round(test_acc, 4) * 100\n",
    "            \n",
    "#             roc_auc_score_acc = roc_auc_score(y_test, y_pred)\n",
    "#             roc_auc_score_acc = round(roc_auc_score_acc, 4) * 100\n",
    "            \n",
    "\n",
    "#             row = [names[j],   i,   train_acc, test_acc, roc_auc_score_acc]\n",
    "            row = [names[j],   i,   train_acc, test_acc]\n",
    "    \n",
    "            rows.append(row)\n",
    "            \n",
    "    models_df = pd.DataFrame(rows) \n",
    "    \n",
    "    models_df.columns = columns_name\n",
    "    print(models_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Model  Random_state  Train_acc  Test_acc\n",
      "0  XGBClassifier             1      69.48     68.88\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "# names_regression = [ \"LightGBM\", \"RF\", \"XGBoost\" , \"SVM\"]\n",
    "# algorithms = [ LGBMClassifier(), RandomForestClassifier(), XGBClassifier(), SVC()]\n",
    "\n",
    "# columns_name = [\"Model\",    \"Random_state\",   'Train_acc',     \"Test_acc\" , \"roc_auc_score\"]\n",
    "\n",
    "names_regression = [ \"XGBClassifier\"]\n",
    "algorithms = [ XGBClassifier(max_depth=5, objective='multi:softmax', num_classes=3)]\n",
    "\n",
    "columns_name = [\"Model\",    \"Random_state\",   'Train_acc',     \"Test_acc\" ]\n",
    "\n",
    "\n",
    "random_state_list_up_to_10 = [1]\n",
    "\n",
    "\n",
    "addRandomStateForAlgorithm(X,Y,names_regression,algorithms,columns_name,random_state_list_up_to_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.05301\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.05261\n",
      "[3]\tvalid_0's multi_logloss: 1.05197\n",
      "[4]\tvalid_0's multi_logloss: 1.0513\n",
      "[5]\tvalid_0's multi_logloss: 1.05037\n",
      "[6]\tvalid_0's multi_logloss: 1.05002\n",
      "[7]\tvalid_0's multi_logloss: 1.04963\n",
      "[8]\tvalid_0's multi_logloss: 1.049\n",
      "[9]\tvalid_0's multi_logloss: 1.04884\n",
      "[10]\tvalid_0's multi_logloss: 1.04843\n",
      "[11]\tvalid_0's multi_logloss: 1.04806\n",
      "[12]\tvalid_0's multi_logloss: 1.04795\n",
      "[13]\tvalid_0's multi_logloss: 1.04727\n",
      "[14]\tvalid_0's multi_logloss: 1.04685\n",
      "[15]\tvalid_0's multi_logloss: 1.04652\n",
      "[16]\tvalid_0's multi_logloss: 1.04607\n",
      "[17]\tvalid_0's multi_logloss: 1.04545\n",
      "[18]\tvalid_0's multi_logloss: 1.04509\n",
      "[19]\tvalid_0's multi_logloss: 1.04465\n",
      "[20]\tvalid_0's multi_logloss: 1.04451\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 1.04451\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X ,Y , test_size = 0.05 , random_state = 10)\n",
    "\n",
    "\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "params = {'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class':4,\n",
    "    'metric': 'multi_logloss',\n",
    "    'learning_rate': 0.002296,\n",
    "    'max_depth': 7,\n",
    "    'num_leaves': 17,\n",
    "    'feature_fraction': 0.4,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'bagging_freq': 17}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred_final = gbm.predict(df3_test, num_iteration=gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_final = XGBClassifier(\n",
    "#  learning_rate =0.1,\n",
    "#  n_estimators=1000,\n",
    "#  max_depth=5,\n",
    "#  min_child_weight=1,\n",
    "#  gamma=0,\n",
    "#  subsample=0.8,\n",
    "#  colsample_bytree=0.8,\n",
    "#  objective= 'binary:logistic',\n",
    "#  nthread=4,\n",
    "#  scale_pos_weight=1,\n",
    "#  seed=27)\n",
    "\n",
    "# model_final = XGBClassifier(max_depth=5, objective='multi:softmax', num_classes=3)\n",
    "\n",
    "\n",
    "# model_final.fit(X, Y)\n",
    "\n",
    "# y_pred_final = model_final.predict(df3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87395, 13) (87395, 2) 87395\n"
     ]
    }
   ],
   "source": [
    "submission_1 = submission.copy()\n",
    "\n",
    "print(df_test.shape , submission.shape , len(y_pred_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00369591e-15 1.00006445e-15 9.99272686e-16 ... 1.00393520e-15\n",
      " 9.99706876e-16 9.99606503e-16]\n"
     ]
    }
   ],
   "source": [
    "submission_1[\"Surge_Pricing_Type\"] = y_pred_final\n",
    "\n",
    "print(submission_1[\"Surge_Pricing_Type\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "submission_1.to_csv('submission_7_LightGBM.csv', index=False)\n",
    "\n",
    "df_submission_1 = pd.read_csv('submission_7_LightGBM.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87395, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip_ID</th>\n",
       "      <th>Surge_Pricing_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T0005689459</td>\n",
       "      <td>1.003696e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T0005689462</td>\n",
       "      <td>1.000064e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T0005689463</td>\n",
       "      <td>9.992727e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Trip_ID  Surge_Pricing_Type\n",
       "0  T0005689459        1.003696e-15\n",
       "1  T0005689462        1.000064e-15\n",
       "2  T0005689463        9.992727e-16"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_submission_1.shape)\n",
    "\n",
    "df_submission_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
